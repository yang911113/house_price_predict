{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8606ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(894, 290)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RegionID</th>\n",
       "      <th>SizeRank</th>\n",
       "      <th>RegionName</th>\n",
       "      <th>RegionType</th>\n",
       "      <th>StateName</th>\n",
       "      <th>1/31/2000</th>\n",
       "      <th>2/29/2000</th>\n",
       "      <th>3/31/2000</th>\n",
       "      <th>4/30/2000</th>\n",
       "      <th>5/31/2000</th>\n",
       "      <th>...</th>\n",
       "      <th>12/31/2022</th>\n",
       "      <th>1/31/2023</th>\n",
       "      <th>2/28/2023</th>\n",
       "      <th>3/31/2023</th>\n",
       "      <th>4/30/2023</th>\n",
       "      <th>5/31/2023</th>\n",
       "      <th>6/30/2023</th>\n",
       "      <th>7/31/2023</th>\n",
       "      <th>8/31/2023</th>\n",
       "      <th>9/30/2023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>394913</td>\n",
       "      <td>1</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>msa</td>\n",
       "      <td>NY</td>\n",
       "      <td>214314.5418</td>\n",
       "      <td>215225.2576</td>\n",
       "      <td>216144.4084</td>\n",
       "      <td>218006.9635</td>\n",
       "      <td>219935.7038</td>\n",
       "      <td>...</td>\n",
       "      <td>602603.0589</td>\n",
       "      <td>601790.7385</td>\n",
       "      <td>600445.3576</td>\n",
       "      <td>600758.0745</td>\n",
       "      <td>602748.9688</td>\n",
       "      <td>606745.1232</td>\n",
       "      <td>610879.6143</td>\n",
       "      <td>614451.3524</td>\n",
       "      <td>617722.7724</td>\n",
       "      <td>620426.4827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>753899</td>\n",
       "      <td>2</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>msa</td>\n",
       "      <td>CA</td>\n",
       "      <td>225004.5438</td>\n",
       "      <td>225841.8461</td>\n",
       "      <td>226957.1249</td>\n",
       "      <td>229176.1551</td>\n",
       "      <td>231603.0784</td>\n",
       "      <td>...</td>\n",
       "      <td>893828.1579</td>\n",
       "      <td>885384.4667</td>\n",
       "      <td>874288.3529</td>\n",
       "      <td>864349.4672</td>\n",
       "      <td>861930.4039</td>\n",
       "      <td>865780.1656</td>\n",
       "      <td>873714.4562</td>\n",
       "      <td>885120.3977</td>\n",
       "      <td>898920.6030</td>\n",
       "      <td>912854.6032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>394463</td>\n",
       "      <td>3</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>msa</td>\n",
       "      <td>IL</td>\n",
       "      <td>149670.2487</td>\n",
       "      <td>149808.7998</td>\n",
       "      <td>150072.6727</td>\n",
       "      <td>150729.1229</td>\n",
       "      <td>151518.7536</td>\n",
       "      <td>...</td>\n",
       "      <td>287482.3014</td>\n",
       "      <td>286885.9368</td>\n",
       "      <td>286735.4858</td>\n",
       "      <td>287367.7020</td>\n",
       "      <td>289026.7412</td>\n",
       "      <td>291175.5936</td>\n",
       "      <td>293687.0706</td>\n",
       "      <td>296179.3135</td>\n",
       "      <td>298585.6638</td>\n",
       "      <td>300379.1909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>394514</td>\n",
       "      <td>4</td>\n",
       "      <td>Dallas, TX</td>\n",
       "      <td>msa</td>\n",
       "      <td>TX</td>\n",
       "      <td>125827.1841</td>\n",
       "      <td>125883.2279</td>\n",
       "      <td>125947.6561</td>\n",
       "      <td>126114.9693</td>\n",
       "      <td>126335.5671</td>\n",
       "      <td>...</td>\n",
       "      <td>375101.6301</td>\n",
       "      <td>372559.5569</td>\n",
       "      <td>370293.4148</td>\n",
       "      <td>368756.1685</td>\n",
       "      <td>368204.4317</td>\n",
       "      <td>368490.4546</td>\n",
       "      <td>369308.9750</td>\n",
       "      <td>370286.4448</td>\n",
       "      <td>371208.7878</td>\n",
       "      <td>371624.0281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>394692</td>\n",
       "      <td>5</td>\n",
       "      <td>Houston, TX</td>\n",
       "      <td>msa</td>\n",
       "      <td>TX</td>\n",
       "      <td>120858.3330</td>\n",
       "      <td>120880.8452</td>\n",
       "      <td>120796.4611</td>\n",
       "      <td>120846.9009</td>\n",
       "      <td>120893.4300</td>\n",
       "      <td>...</td>\n",
       "      <td>305224.4451</td>\n",
       "      <td>303461.4198</td>\n",
       "      <td>301787.5004</td>\n",
       "      <td>300640.5033</td>\n",
       "      <td>300192.7671</td>\n",
       "      <td>300347.4117</td>\n",
       "      <td>301151.1126</td>\n",
       "      <td>302072.6358</td>\n",
       "      <td>302946.5474</td>\n",
       "      <td>303302.7017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 290 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RegionID  SizeRank       RegionName RegionType StateName    1/31/2000  \\\n",
       "0    394913         1     New York, NY        msa        NY  214314.5418   \n",
       "1    753899         2  Los Angeles, CA        msa        CA  225004.5438   \n",
       "2    394463         3      Chicago, IL        msa        IL  149670.2487   \n",
       "3    394514         4       Dallas, TX        msa        TX  125827.1841   \n",
       "4    394692         5      Houston, TX        msa        TX  120858.3330   \n",
       "\n",
       "     2/29/2000    3/31/2000    4/30/2000    5/31/2000  ...   12/31/2022  \\\n",
       "0  215225.2576  216144.4084  218006.9635  219935.7038  ...  602603.0589   \n",
       "1  225841.8461  226957.1249  229176.1551  231603.0784  ...  893828.1579   \n",
       "2  149808.7998  150072.6727  150729.1229  151518.7536  ...  287482.3014   \n",
       "3  125883.2279  125947.6561  126114.9693  126335.5671  ...  375101.6301   \n",
       "4  120880.8452  120796.4611  120846.9009  120893.4300  ...  305224.4451   \n",
       "\n",
       "     1/31/2023    2/28/2023    3/31/2023    4/30/2023    5/31/2023  \\\n",
       "0  601790.7385  600445.3576  600758.0745  602748.9688  606745.1232   \n",
       "1  885384.4667  874288.3529  864349.4672  861930.4039  865780.1656   \n",
       "2  286885.9368  286735.4858  287367.7020  289026.7412  291175.5936   \n",
       "3  372559.5569  370293.4148  368756.1685  368204.4317  368490.4546   \n",
       "4  303461.4198  301787.5004  300640.5033  300192.7671  300347.4117   \n",
       "\n",
       "     6/30/2023    7/31/2023    8/31/2023    9/30/2023  \n",
       "0  610879.6143  614451.3524  617722.7724  620426.4827  \n",
       "1  873714.4562  885120.3977  898920.6030  912854.6032  \n",
       "2  293687.0706  296179.3135  298585.6638  300379.1909  \n",
       "3  369308.9750  370286.4448  371208.7878  371624.0281  \n",
       "4  301151.1126  302072.6358  302946.5474  303302.7017  \n",
       "\n",
       "[5 rows x 290 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "price = pd.read_csv(\"Data.csv\")\n",
    "\n",
    "date_columns = price.columns[5:]\n",
    "\n",
    "print(price.shape)\n",
    "price.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a609f0",
   "metadata": {},
   "source": [
    "## 1. Handling Outliers (Excessively Large/Small Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99c2bb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value in DataFrame:  999999999.0\n",
      "Min value in DataFrame:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Price columns\n",
    "date_columns = price.columns[5:]\n",
    "\n",
    "# Check Excessively Large/Small Values\n",
    "stats = price[date_columns].describe()\n",
    "\n",
    "# Max & Min value in each columns\n",
    "max_per_column = stats.loc['max']\n",
    "min_per_column = stats.loc['min']\n",
    "\n",
    "# Check Max & Min value of dataframe\n",
    "overall_max = max_per_column.max()\n",
    "overall_min = min_per_column.min()\n",
    "\n",
    "print(\"Max value in DataFrame: \", overall_max)\n",
    "print(\"Min value in DataFrame: \", overall_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3afc3656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20867/2005917448.py:34: RuntimeWarning: invalid value encountered in greater\n",
      "  outliers = (values > upper_thresh) | (values < lower_thresh)\n",
      "/tmp/ipykernel_20867/2005917448.py:34: RuntimeWarning: invalid value encountered in less\n",
      "  outliers = (values > upper_thresh) | (values < lower_thresh)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "整个 DataFrame 的最大值: 1610331.33\n",
      "整个 DataFrame 的最小值: 10761.2424\n",
      "所有异常值均已成功替换，最大值不超过 2,000,000，最小值不低于 10,000。\n",
      "\n",
      "每个日期列中大于上限阈值的异常值数量：\n",
      "1/31/2000    0\n",
      "2/29/2000    0\n",
      "3/31/2000    0\n",
      "4/30/2000    0\n",
      "5/31/2000    0\n",
      "            ..\n",
      "5/31/2023    0\n",
      "6/30/2023    0\n",
      "7/31/2023    0\n",
      "8/31/2023    0\n",
      "9/30/2023    0\n",
      "Length: 285, dtype: int64\n",
      "\n",
      "每个日期列中小于下限阈值的异常值数量：\n",
      "1/31/2000    0\n",
      "2/29/2000    0\n",
      "3/31/2000    0\n",
      "4/30/2000    0\n",
      "5/31/2000    0\n",
      "            ..\n",
      "5/31/2023    0\n",
      "6/30/2023    0\n",
      "7/31/2023    0\n",
      "8/31/2023    0\n",
      "9/30/2023    0\n",
      "Length: 285, dtype: int64\n",
      "所有异常值和缺失值均已成功替换。\n"
     ]
    }
   ],
   "source": [
    "# 2. 确保日期列的数据类型为数值类型\n",
    "price[date_columns] = price[date_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 3. Thresholds\n",
    "upper_threshold = 2_000_000\n",
    "lower_threshold = 10_000\n",
    "\n",
    "def replace_outliers(row, date_cols, upper_thresh, lower_thresh):\n",
    "\n",
    "    values = row[date_cols].values\n",
    "    n = len(values)\n",
    "    \n",
    "    # 标记异常值：大于上限或小于下限\n",
    "    outliers = (values > upper_thresh) | (values < lower_thresh)\n",
    "    \n",
    "    # 初始化替换值列表\n",
    "    replacement_values = values.copy()\n",
    "    \n",
    "    i = 0\n",
    "    while i < n:\n",
    "        if outliers[i]:\n",
    "            # 记录连续异常值的起始和结束位置\n",
    "            start = i\n",
    "            while i < n and outliers[i]:\n",
    "                i += 1\n",
    "            end = i - 1\n",
    "            \n",
    "            # 找到左邻居\n",
    "            left = start - 1\n",
    "            while left >= 0 and outliers[left]:\n",
    "                left -= 1\n",
    "            left_value = values[left] if left >= 0 else np.nan\n",
    "            \n",
    "            # 找到右邻居\n",
    "            right = end + 1\n",
    "            while right < n and outliers[right]:\n",
    "                right += 1\n",
    "            right_value = values[right] if right < n else np.nan\n",
    "            \n",
    "            # 计算替换值\n",
    "            if not np.isnan(left_value) and not np.isnan(right_value):\n",
    "                replacement = (left_value + right_value) / 2\n",
    "            elif not np.isnan(left_value):\n",
    "                replacement = left_value\n",
    "            elif not np.isnan(right_value):\n",
    "                replacement = right_value\n",
    "            else:\n",
    "                replacement = np.nan  # 如果左右邻居都不存在非异常值，设为 NaN\n",
    "            \n",
    "            # 替换连续异常值\n",
    "            replacement_values[start:end+1] = replacement\n",
    "        else:\n",
    "            i += 1\n",
    "    \n",
    "    # 返回替换后的值\n",
    "    return pd.Series(replacement_values, index=date_cols)\n",
    "\n",
    "# 4. 应用替换函数到每一行\n",
    "price[date_columns] = price.apply(\n",
    "    lambda row: replace_outliers(row, date_columns, upper_threshold, lower_threshold),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 5. 验证替换结果\n",
    "stats = price[date_columns].describe()\n",
    "\n",
    "# 提取每个日期列的最大值和最小值\n",
    "max_per_column = stats.loc['max']\n",
    "min_per_column = stats.loc['min']\n",
    "\n",
    "# 计算整个 DataFrame 的最大值和最小值\n",
    "overall_max = max_per_column.max()\n",
    "overall_min = min_per_column.min()\n",
    "\n",
    "print(\"整个 DataFrame 的最大值:\", overall_max)\n",
    "print(\"整个 DataFrame 的最小值:\", overall_min)\n",
    "\n",
    "# 检查是否存在仍大于上限或小于下限的值\n",
    "if overall_max > upper_threshold or overall_min < lower_threshold:\n",
    "    print(\"警告: 仍存在大于上限阈值或小于下限阈值的值。\")\n",
    "else:\n",
    "    print(\"所有异常值均已成功替换，最大值不超过 2,000,000，最小值不低于 10,000。\")\n",
    "\n",
    "# 6. （可选）统计每列中异常值的数量\n",
    "upper_outliers = (price[date_columns] > upper_threshold).sum()\n",
    "lower_outliers = (price[date_columns] < lower_threshold).sum()\n",
    "\n",
    "print(\"\\n每个日期列中大于上限阈值的异常值数量：\")\n",
    "print(upper_outliers)\n",
    "\n",
    "print(\"\\n每个日期列中小于下限阈值的异常值数量：\")\n",
    "print(lower_outliers)\n",
    "\n",
    "# 7. （可选）进一步处理替换过程中产生的 NaN 值\n",
    "\n",
    "# 使用线性插值填补缺失值，沿着列方向（axis=1）\n",
    "price[date_columns] = price[date_columns].interpolate(method='linear', axis=1, limit_direction='both')\n",
    "\n",
    "# 使用后向填充填补起始缺失值\n",
    "price[date_columns] = price[date_columns].fillna(method='bfill', axis=1)\n",
    "\n",
    "# 使用前向填充填补结束缺失值\n",
    "price[date_columns] = price[date_columns].fillna(method='ffill', axis=1)\n",
    "\n",
    "# 使用每行的均值填补剩余的缺失值\n",
    "price[date_columns] = price[date_columns].apply(\n",
    "    lambda row: row.fillna(row.mean()), axis=1\n",
    ")\n",
    "\n",
    "# 最终检查是否还有缺失值\n",
    "missing_after_all = price[date_columns].isna().sum().sum()\n",
    "if missing_after_all > 0:\n",
    "    print(f\"仍有 {missing_after_all} 个缺失值未被替换。\")\n",
    "    # 根据需要选择进一步的填补策略\n",
    "else:\n",
    "    print(\"所有异常值和缺失值均已成功替换。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d0af26",
   "metadata": {},
   "source": [
    "## Non Numeric data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "957ad5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "非数值单元格的位置及其值：\n",
      "\n",
      "每个日期列中非数值单元格的数量：\n",
      "1/31/2000    0\n",
      "2/29/2000    0\n",
      "3/31/2000    0\n",
      "4/30/2000    0\n",
      "5/31/2000    0\n",
      "            ..\n",
      "5/31/2023    0\n",
      "6/30/2023    0\n",
      "7/31/2023    0\n",
      "8/31/2023    0\n",
      "9/30/2023    0\n",
      "Length: 285, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 2. 定义一个函数来检查是否为数值\n",
    "def is_numeric(x):\n",
    "    try:\n",
    "        float(x)\n",
    "        return True\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "# 3. 应用函数到 date_columns，创建一个布尔 DataFrame，True 表示数值，False 表示非数值\n",
    "numeric_mask = price[date_columns].applymap(is_numeric)\n",
    "\n",
    "# 4. 标记非数值单元格\n",
    "non_numeric_mask = ~numeric_mask\n",
    "\n",
    "# 5. 提取非数值单元格的位置和对应的值\n",
    "# 使用 stack 将 DataFrame 转换为 Series，方便筛选\n",
    "non_numeric_locations = non_numeric_mask.stack()\n",
    "\n",
    "# 过滤出非数值为 True 的位置\n",
    "non_numeric_locations = non_numeric_locations[non_numeric_locations]\n",
    "\n",
    "# 获取对应的行索引和列名\n",
    "non_numeric_indices = non_numeric_locations.index.tolist()\n",
    "\n",
    "# 打印所有非数值单元格的位置及其值\n",
    "print(\"非数值单元格的位置及其值：\")\n",
    "for row, col in non_numeric_indices:\n",
    "    cell_value = price.at[row, col]\n",
    "    print(f\"行索引: {row}, 列名: '{col}', 值: {cell_value}\")\n",
    "\n",
    "# 6. （可选）统计每列中非数值单元格的数量\n",
    "non_numeric_counts = non_numeric_mask.sum()\n",
    "\n",
    "print(\"\\n每个日期列中非数值单元格的数量：\")\n",
    "print(non_numeric_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6885845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "插值后剩余缺失值数量: 0\n",
      "所有缺失值均已通过插值方法成功填补。\n"
     ]
    }
   ],
   "source": [
    "# 确保日期列的数据类型为数值类型\n",
    "price[date_columns] = price[date_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 使用线性插值方法填补缺失值，沿着列方向（axis=1）\n",
    "price[date_columns] = price[date_columns].interpolate(method='linear', axis=1, limit_direction='both')\n",
    "\n",
    "# 验证是否还有缺失值\n",
    "missing_after_interpolation = price[date_columns].isna().sum().sum()\n",
    "print(f\"插值后剩余缺失值数量: {missing_after_interpolation}\")\n",
    "\n",
    "if missing_after_interpolation > 0:\n",
    "    print(\"存在仍未填补的缺失值，进行进一步处理。\")\n",
    "else:\n",
    "    print(\"所有缺失值均已通过插值方法成功填补。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54bcad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "price.to_csv(\"Data_cleaned.csv\",index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafca6fb",
   "metadata": {},
   "source": [
    "## Modeling Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c7a866",
   "metadata": {},
   "source": [
    "Convert the data into a format suitable for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77651959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取Excel文件\n",
    "df = pd.read_csv('Data_cleaned.csv')\n",
    "\n",
    "# 查看数据列名\n",
    "print(df.columns)\n",
    "\n",
    "# 选择从F列开始的房价列\n",
    "price_columns = df.columns[5:]  \n",
    "\n",
    "for column in price_columns:\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "\n",
    "# 将数据转换为长格式\n",
    "df_long = df.melt(id_vars=['RegionID', 'SizeRank', 'RegionName', 'RegionType', 'StateName'],\n",
    "                  value_vars=df.columns[5:],  # 选择从第6列开始的月份列\n",
    "                  var_name='Date',\n",
    "                  value_name='Price')\n",
    "\n",
    "# 将 'Date' 列转换为 datetime 类型\n",
    "df_long['Date'] = pd.to_datetime(df_long['Date'], format='%m/%d/%Y')\n",
    "\n",
    "# 按 RegionName 分组\n",
    "df_long.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7352103c",
   "metadata": {},
   "source": [
    "Get predicted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fe6966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# 假设 df_long 是您的原始数据框\n",
    "# 创建一个新的 DataFrame 用来保存预测结果\n",
    "df_forecasted = df_long.copy()\n",
    "\n",
    "# 获取所有唯一的地区名称\n",
    "regions = df_long['RegionName'].unique()\n",
    "\n",
    "# 创建一个列表来保存预测结果\n",
    "forecast_list = []\n",
    "\n",
    "# 遍历所有地区进行预测\n",
    "for region in regions:\n",
    "    print(region)\n",
    "    region_data = df_long[df_long['RegionName'] == region]\n",
    "    region_data = region_data.dropna()\n",
    "    \n",
    "    # 只保留 'Price' 列作为时间序列数据\n",
    "    region_data = region_data[['Price']]\n",
    "    \n",
    "    # 使用SARIMAX模型进行建模\n",
    "    model = SARIMAX(region_data, \n",
    "                    order=(0, 1, 0),  # 非季节性部分 (p, d, q)\n",
    "                    seasonal_order=(1, 1, 0, 12))  # 季节性部分 (P, D, Q, S)\n",
    "    model_fit = model.fit()\n",
    "    \n",
    "    # 预测未来5个月的价格\n",
    "    forecast_steps = 5\n",
    "    forecast = model_fit.forecast(steps=forecast_steps)\n",
    "    \n",
    "    # 创建新的列名，例如 'Forecast_Price'\n",
    "    forecast_column = f'{region}'\n",
    "    \n",
    "    # 将预测值填入 df_forecasted 中，扩展预测数据到 df_forecasted\n",
    "    #forecast_index = pd.date_range(start=region_data.index[-1] + pd.Timedelta(days=1), \n",
    "                                   #periods=forecast_steps, freq='M')\n",
    "\n",
    "    forecast_index = ['2023-10-31', '2023-11-30', '2023-12-31', '2024-01-31', '2024-02-29']\n",
    "    forecast_index = pd.to_datetime(forecast_index)\n",
    "    forecast_series = pd.Series(forecast.values, index=forecast_index, name=forecast_column)\n",
    "    \n",
    "    # 将 Series 转换为 DataFrame\n",
    "    df = forecast_series.to_frame()\n",
    "    \n",
    "    # 重命名列\n",
    "    df.columns = ['Price']\n",
    "    \n",
    "    # 添加 RegionName 列，所有行都为 'Ludington, MI'\n",
    "    df['RegionName'] = forecast_series.name\n",
    "    \n",
    "    # 重置索引，并将索引列名更改为 'Date'\n",
    "    df = df.reset_index()\n",
    "    df.rename(columns={'index': 'Date'}, inplace=True)\n",
    "    \n",
    "    # 按照期望的格式排列列\n",
    "    df = df[['Date', 'RegionName', 'Price']]\n",
    "    df.set_index('Date', inplace=True)\n",
    "    print(df)\n",
    "\n",
    "    forecast_list.append(df)\n",
    "\n",
    "df_combined = pd.concat(forecast_list, ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db2561d",
   "metadata": {},
   "source": [
    "Combine predicted value into orginial dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2b0219",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/yzhang3/Desktop/Data_cleaned.csv')\n",
    "# 将 df2 的列名中的日期部分转换为标准格式\n",
    "date_columns = ['10/31/2023', '11/30/2023', '12/31/2023', '01/31/2024', '02/29/2024']\n",
    "formatted_dates = pd.to_datetime(date_columns)\n",
    "\n",
    "print(date_columns, formatted_dates)\n",
    "\n",
    "# 遍历 df2 的每一行\n",
    "for i, row in df.iterrows():\n",
    "    # 获取当前行的 RegionName\n",
    "    region_name = row['RegionName']\n",
    "    \n",
    "    # 遍历每个日期列\n",
    "    for date, col in zip(formatted_dates, date_columns):\n",
    "        # 检查 df1 中是否有对应的日期和 RegionName\n",
    "        if date in df_combined.index and not df_combined[df_combined['RegionName'] == region_name].empty:\n",
    "            # 获取价格\n",
    "            matching_price = df_combined.loc[(df_combined.index == date) & (df_combined['RegionName'] == region_name), 'Price']\n",
    "            if not matching_price.empty:\n",
    "                # 填充到 df2 的对应列\n",
    "                df.at[i, col] = matching_price.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3379965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Data_with_predict.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
